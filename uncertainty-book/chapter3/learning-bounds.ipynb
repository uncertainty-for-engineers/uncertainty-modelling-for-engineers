{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sec:interval-predictor-models)=\n",
    "Learning bounds on a model\n",
    "--------------------------\n",
    "\n",
    "Instead of learning a probability distribution to describe the effect of\n",
    "one variable on another, one may instead attempt to learn a function\n",
    "which maps the input variables to an interval representing the possible\n",
    "range of the output. Such models are known as interval predictor models.\n",
    "Sometimes the predicted intervals have an associated confidence level\n",
    "(or a bound on the confidence level), and as such they can be considered\n",
    "as bounds on the quantiles of a random variable\n",
    "{cite}`dabney2017distributional`. Typically the obtained intervals represent\n",
    "an outer approximation, i.e. the intervals are overly wide and hence\n",
    "conservative in an engineering sense. An interval predictor model can be\n",
    "seen as prescribing the support of a Random Predictor Model, which is\n",
    "defined as a function which maps input variables to an output random\n",
    "variable. A Gaussian Process Model is a specific case of a Random\n",
    "Predictor Model.\n",
    "\n",
    "In this section, we describe how interval predictor models can be\n",
    "trained in practice. We then describe how the theory of scenario\n",
    "optimisation can be used to provide guaranteed bounds on the reliability\n",
    "of the trained interval predictor models, for the purpose of validation.\n",
    "\n",
    "### Training interval predictor models\n",
    "\n",
    "Let us consider a black box model (sometimes referred to as the Data\n",
    "Generating Mechanism or DGM) which acts on a vector of input variables\n",
    "$x \\in \\mathbb{R}^{n_x}$ to produce an output $y \\in \\mathbb{R}$. We\n",
    "wish to obtain the two functions $\\overline{y}(x)$ and\n",
    "$\\underline{y}(x)$ which enclose a fraction, $\\epsilon$, of samples from\n",
    "the DGM, i.e. samples of $y(x)$ where $x$ is sampled from some unknown\n",
    "probability density. The functions $\\overline{y}(x)$ and\n",
    "$\\underline{y}(x)$ are bounds on a prediction interval, and as such we\n",
    "wish them to be as tight as possible. This can be written as a so-called\n",
    "chance constrained optimisation program:\n",
    "$\\operatorname{argmin}_{\\boldsymbol{p}}{\\{\\mathbb{E}_x(\\overline{y}_{\\boldsymbol{p}}(x) - \\underline{y}_{\\boldsymbol{p}}(x)) : P\\{\\overline{y}_{\\boldsymbol{p}}(x) > y(x) > \\underline{y}_{\\boldsymbol{p}}(x) \\} \\le \\epsilon\\}},$\n",
    "where $\\boldsymbol{p}$ is a vector of function parameters to be\n",
    "identified, and $\\epsilon$ is a parameter which constrains how often the\n",
    "constraints may be violated. Chance constrained optimisation programs\n",
    "can be solved by using a so-called scenario program, where the chance\n",
    "constraint is replaced with multiple sampled constraints based on data,\n",
    "i.e.\n",
    "```{math}\n",
    ":label: ch3:ipm_op\n",
    "\\operatorname{argmin}_{\\boldsymbol{p}}{\\{\\mathbb{E}_x(\\overline{y}_{\\boldsymbol{p}}(x) - \\underline{y}_{\\boldsymbol{p}}(x)) : \\overline{y}_{\\boldsymbol{p}}(x^{(i)}) > y^{(i)} > \\underline{y}_{\\boldsymbol{p}}(x^{(i)}), i=1,...,N\\}},\n",
    "```\n",
    "where\n",
    "$\\mathcal{X}_\\text{train} = \\{ \\{x^{(1)}, y^{(1)}\\}, ..., \\{x^{(n)}, y^{(n)}\\} \\}$\n",
    "are sampled from the DGM. Most of the literature on scenario\n",
    "optimisation Theory aims to obtain bounds on $\\epsilon$. Finding bounds\n",
    "on $\\epsilon$ using scenario optimisation is easier in practice than\n",
    "other similar methods in statistical learning theory, since no knowledge\n",
    "of the Vapnik-Chervonenkis dimension (a measure of the capacity of the\n",
    "model, which is difficult to determine exactly) is required.\n",
    "\n",
    "A key advantage over other machine learning techniques is that interval\n",
    "training data (i.e. where the training data inputs are given in the form\n",
    "$x^{(i)} \\in [\\underline{x}^{(i)}, \\overline{x}^{(i)}]$ due to epistemic\n",
    "uncertainty or some other reason) fits into the scenario optimisation\n",
    "framework coherently {cite}`lacerda2017interval`. This can be seen as\n",
    "equivalent to defending against the attack model of adversarial examples\n",
    "considered by {cite}`madry2017towards`, where the network is trained to produce\n",
    "the same outputs for small perturbations of the input data. The\n",
    "framework also permits robustness against uncertainty in training\n",
    "outputs, i.e. $y^{(i)} \\in [\\underline{y}^{(i)}, \\overline{y}^{(i)}]$,\n",
    "where $y^{(i)}$ is a single training example output.\n",
    "\n",
    "#### Convex interval predictor models\n",
    "\n",
    "If the objective and constraints for the scenario program are convex\n",
    "then the program can be easily solved, and bounds can be put on\n",
    "$\\epsilon$. We will approximate the DGM with an interval predictor model\n",
    "(IPM) which returns an interval for each vector $x\\in X$, the set of\n",
    "inputs, given by\n",
    "```{math}\n",
    ":label: eq:2\n",
    "I_y(x,P)= \\big\\{ y=G(x,\\boldsymbol{p}),\\boldsymbol{p} \\in P \\big\\},\n",
    "```\n",
    "where $G$ is an arbitrary function and $\\boldsymbol{p}$ is a parameter\n",
    "vector. By making an approximation for $G$ and considering a linear\n",
    "parameter dependency {eq}`eq:2` becomes\n",
    "$I_y(x,P)=\\big\\{ y=\\boldsymbol{p}^{T} \\phi (x),\\boldsymbol{p} \\in P \\big\\} ,$\n",
    "where $\\phi (x)$ is a basis (polynomial and radial bases are commonly\n",
    "used), and $\\boldsymbol{p}$ is a member of a convex parameter set. The\n",
    "convex parameter set is usually assumed to be either ellipsoidal or\n",
    "hyper-rectangular {cite}`campi2009interval`. {cite}`crespo_interval_2016`\n",
    "demonstrates that hyper-rectangular parameters sets result in an IPM\n",
    "with bounds with a convenient analytical form. The hyper-rectangular\n",
    "parameter uncertainty set can be defined as\n",
    "$P=\\big\\{\\boldsymbol{p}:\\underline{\\boldsymbol{p}} \\leq \\boldsymbol{p} \\leq \\overline{\\boldsymbol{p}} \\big\\},$\n",
    "where $\\underline{\\boldsymbol{p}}$ and $\\overline{\\boldsymbol{p}}$ are\n",
    "parameter vectors specifying the defining vertices of the hyper\n",
    "rectangular uncertainty set. The IPM with linear parameter dependency on\n",
    "the hyper-rectangular uncertain set of parameters is defined by the\n",
    "interval\n",
    "$I_y(x,P)=[\\underline{y}(x,\\overline{\\boldsymbol{p}},\\underline{\\boldsymbol{p}}),\\overline{y}(x,\\overline{\\boldsymbol{p}},\\underline{\\boldsymbol{p}})],$\n",
    "where $\\underline{y}$ and $\\overline{y}$ are the lower and upper bounds\n",
    "of the IPM, respectively. Explicitly, the lower bound is given by\n",
    "$\\underline{y}(x,\\overline{\\boldsymbol{p}},\\underline{\\boldsymbol{p}}) = \\overline{\\boldsymbol{p}} ^T \\left(\n",
    "      \\frac{\\phi(x)-|\\phi(x)|}{2}\n",
    "      \\right)+\\underline{\\boldsymbol{p}} ^T \\left(\n",
    "      \\frac{\\phi(x)+|\\phi(x)|}{2}\n",
    "      \\right),$ and the upper bound is given by\n",
    "$\\overline{y}(x,\\overline{\\boldsymbol{p}},\\underline{\\boldsymbol{p}}) = \\overline{\\boldsymbol{p}} ^T \\left(\n",
    "      \\frac{\\phi(x)+|\\phi(x)|}{2}\n",
    "      \\right)+\\underline{\\boldsymbol{p}} ^T \\left(\n",
    "      \\frac{\\phi(x)-|\\phi(x)|}{2}\n",
    "      \\right).$ To identify the hyper-rectangular uncertainty set one\n",
    "trains the IPM by minimising the value of\n",
    "$\\delta_y(x,\\overline{\\boldsymbol{p}},\\underline{\\boldsymbol{p}})=(\\overline{\\boldsymbol{p}}-\\underline{\\boldsymbol{p}})^T |\\phi (x) |,$\n",
    "subject to the constraint that the training data points fall inside the\n",
    "bounds on the IPM, by solving the linear and convex optimisation problem\n",
    "\n",
    "```{math}\n",
    ":label: op\n",
    "\\big\\{\\hat{\\underline{\\boldsymbol{p}}} , \\hat{\\overline{\\boldsymbol{p}}} \\big\\}=\\operatorname{argmin}_{\\boldsymbol{u},\\boldsymbol{v}} \\big\\{\\mathbb{E}_x[\\delta_y(x,\\boldsymbol{v},\\boldsymbol{u})] : \\underline{y}(x^{(i)},\\boldsymbol{v},\\boldsymbol{u}) \\leq y^{(i)} \\leq \\overline{y}(x^{(i)},\\boldsymbol{v},\\boldsymbol{u}), \\boldsymbol{u} \\leq \\boldsymbol{v} \\big\\}.\n",
    "```\n",
    "The constraints ensure that all data points to be fitted lie within the\n",
    "bounds and that the upper bound is greater than the lower bound. This\n",
    "combination of objective function and constraints is linear and convex\n",
    "{cite}`crespo_interval_2016`. In this thesis all interval predictor models\n",
    "have polynomial bases, i.e. $\\phi(x)=\\left[1,x^{i_2},x^{i_3},...\\right]$\n",
    "with $x=[x_a,x_b,...]$ and $i_j=[i_{j,a},i_{j,b},...]$ with $i_j\\ne i_k$\n",
    "for $j\\ne k$.\n",
    "\n",
    "For illustrative purposes an example degree 2 IPM is shown without\n",
    "training data points in\n",
    "{ref}`fig:sub1`. The hyper rectangular uncertainty set\n",
    "corresponding to the IPM in\n",
    "{ref}`fig:sub1` is plotted in\n",
    "{ref}`fig:sub2`. The\n",
    "discontinuity observed in the upper and lower bounds is a consequence of\n",
    "the chosen basis, and can be avoided by choosing a basis where\n",
    "$\\phi(x)=|\\phi(x)|$.\n",
    "\n",
    "```{figure} figures/ipm_explain_1.png\n",
    "---\n",
    "height: 150px\n",
    "name: fig:sub1\n",
    "---\n",
    "The IPM's hyper rectangular uncertainty set plotted in 'parameter\n",
    "space'. The uniformly sampled parameter vectors of the polynomials shown\n",
    "in {ref}`fig:sub2`.\n",
    "```\n",
    "\n",
    "```{figure} figures/IPM_explain_2.png\n",
    "---\n",
    "height: 150px\n",
    "name: fig:sub2\n",
    "---\n",
    "The IPM's hyper rectangular uncertainty set plotted in 'parameter\n",
    "space'. The uniformly sampled parameter vectors of the polynomials shown\n",
    "in {ref}`fig:sub1` are displayed as points in the uncertain\n",
    "set.\n",
    "```\n",
    "\n",
    "#### Non-convex interval predictor models\n",
    "\n",
    "In some circumstances engineers may wish to represent more complex\n",
    "functions with IPMs, and hence the functions used to represent the\n",
    "bounds of the IPM may have more trainable parameters. The interior point\n",
    "method used to solve linear optimisation programs, such as those used\n",
    "for convex IPMs, has complexity $d^2 n_\\text{cons}$, where $d$\n",
    "represents the number of optimisation variables and $n_\\text{cons}$\n",
    "represents the number of constraints in the optimisation (which in this\n",
    "case scales linearly with the number of training data points), and hence\n",
    "the method does not scale well to IPMs with large numbers of trainable\n",
    "parameters {cite}`boyd2004convex`.\n",
    "\n",
    "Neural networks enable uncertainty models to be created with vast\n",
    "numbers of parameters in a feasible computational time. Neural networks\n",
    "with interval outputs were proposed by {cite}`ishibuchi1993architecture`, and\n",
    "further described by {cite}`huang1998robust`. In these papers the learning\n",
    "takes place by identifying the weights $W$, which solve the following\n",
    "program:\n",
    "```{math}\n",
    ":label: eq:ishibuchi\n",
    "\\operatorname{argmin}_{\\overline{W},\\underline{W}}{[\\mathbb{E}_x(\\overline{y}(x)-\\underline{y}(x)) :\\overline{y}(x^{(i)})>y^{(i)}>\\underline{y}(x^{(i)})\\ \\forall \\ i]},\n",
    "```\n",
    "where $\\overline{y}(x)$ and $\\underline{y}(x)$ are obtained from two\n",
    "independent neural networks, such that $\\overline{y}(x)$ and\n",
    "$\\underline{y}(x)$ are the output layers of networks, such as those\n",
    "defined by {eq}`eq:net`. In practice this problem is solved by using a mean\n",
    "squared error loss function with a simple penalty function to model the\n",
    "constraints. In general, penalty methods require careful choice of\n",
    "hyper-parameters to guarantee convergence. These neural networks act in\n",
    "a similar way to interval predictor models, however the interval neural\n",
    "networks do not attempt to use the training data set to bound\n",
    "$\\epsilon$. {cite}`freitag2011recurrent` define similar networks with fuzzy\n",
    "parameters to operate on fuzzy data. The fuzzy neural networks are\n",
    "trained by minimising a least square loss function (a set inclusion\n",
    "constraint is not used), which can also be applied to time series data\n",
    "sets. These approaches are very different from the approach of\n",
    "{cite}`patino2004interval`, where a traditional neural network loss function is\n",
    "intervalised using interval arithmetic.\n",
    "\n",
    "{cite}`campi2015non` extended the scenario approach to non-convex optimisation\n",
    "programs, and hence applied the approach to a single layer neural\n",
    "network, with a constant width interval prediction, which was trained\n",
    "using the interior-point algorithm in Matlab. In other words the\n",
    "following program is solved:\n",
    "```{math}\n",
    ":label: constantLine\n",
    "\\operatorname{argmin}_{W,h}{[h : |y^{(i)}-\\hat{y}(x^{(i)})|<h\\ \\forall \\ i]},\n",
    "```\n",
    "where $h$ is a real number, and $\\hat{y}$ represents the central line of\n",
    "the prediction obtained from the same network specified by\n",
    "{eq}`eq:net`. The\n",
    "bounds on the prediction interval are therefore given by\n",
    "$\\overline{y}(x) = \\hat{y}(x) + h$ and\n",
    "$\\underline{y}(x) = \\hat{y}(x) - h$. The constant width interval neural\n",
    "network expresses homoscedastic uncertainty. The solution to the\n",
    "optimisation program in\n",
    "{eq}`constantLine` can also be obtained by finding the neural\n",
    "network weights which minimise the so-called maximum-error loss:\n",
    "```{math}\n",
    ":label: max-error-loss\n",
    "\\mathcal{L}_{\\text{max-error}} = \\max_{i} |y^{(i)}-\\hat{y}(x^{(i)})|, %\\equiv \\lim_{p \\rightarrow \\infty} \\left( \\sum_i |y^{(i)}-\\hat{y}(x^{(i)})|^{p} \\right) ^{\\frac{1}{p}},\n",
    "```\n",
    "where $h$ is the minimum value of the loss.\n",
    "It is trivial to show this is true, since the set inclusion constraint\n",
    "in {eq}`constantLine` requires that $h$ is larger than the absolute\n",
    "error for each data point in the training set {cite}`CARE201871`.\n",
    "\n",
    "In {cite}`sadeghi2019efficient` a back propagation algorithm for Neural Networks with interval predictions is proposed. \n",
    "A modified maximum-error loss is used.\n",
    "The approach can accommodate incertitude in the training data.\n",
    "A key result is that, by using minibatches, the complexity of the proposed approach does not directly depend upon the number of training data points as with other Interval Predictor Model methods. \n",
    "\n",
    "\n",
    "(sec:scenario)=\n",
    "### Validating models with the scenario approach\n",
    "\n",
    "We will first present an overview of the scenario optimisation theory\n",
    "for the validation of models in the convex case, before describing more\n",
    "general techniques which apply in the non-convex case.\n",
    "\n",
    "#### Convex case\n",
    "\n",
    "Intuition tells us that the solution of the scenario program will be\n",
    "most accurate when the dimensionality of the design variable is low and\n",
    "we take as many samples of the constraints as possible (in fact, an\n",
    "infinite number of sampled constraints would allow us to reliably\n",
    "estimate\n",
    "$P\\{\\overline{y}_{\\boldsymbol{p}}(x) > y(x) > \\underline{y}_{\\boldsymbol{p}}(x) \\}$,\n",
    "and hence solve the program exactly). However, in practice obtaining\n",
    "these samples is often an expensive process. Fortunately, the theory of\n",
    "scenario optimisation provides robust bounds on the robustness of the\n",
    "obtained solution. The bounds generally take the following form:\n",
    "$P^n(V(\\hat{z}_n)>\\epsilon)\\le\\beta.$ This equation states that the\n",
    "probability of observing a bad set of data (i.e. a bad set of\n",
    "constraints) in future, such that our solution violates a proportion\n",
    "greater than $\\epsilon$ of the constraints (i.e. $V(\\hat{z}_n)>\\epsilon$\n",
    "where $V(\\hat{z}_n) = \\frac{1}{n} \\sum_i^n {V^{(i)}}$ and $V^{(i)} = 1$\n",
    "only if\n",
    "$\\overline{y}_{\\boldsymbol{p}}(x) > y(x) > \\underline{y}_{\\boldsymbol{p}}(x)$),\n",
    "is no greater than $\\beta$. The scenario approach gives a simple\n",
    "analytic form for the connection between $\\epsilon$ and $\\beta$ in the\n",
    "case that the optimisation program is convex:\n",
    "```{math}\n",
    ":label: convexrel\n",
    "\\beta=\\frac{1}{\\epsilon}\\frac{d}{n+1},\n",
    "```\n",
    "where $n$ is\n",
    "the number of constraint samples in the training data set used to solve\n",
    "the scenario program, and $d$ is the dimensionality of the design\n",
    "variable, $z$. For a fixed $d$ and $n$ we obtain a\n",
    "confidence-reliability plot as shown in\n",
    "{eq}`exampleConvex`. The plot demonstrates that by decreasing\n",
    "$\\epsilon$ slightly, $1-\\beta$ can be made to be insignificantly small.\n",
    "Other tighter bounds exist in the more recent scenario optimisation\n",
    "literature, e.g.\n",
    "{cite}`calafiore2010random` {cite}`campi2008exact` {cite}`alamo2015randomized`, for\n",
    "example\n",
    "```{math}\n",
    ":label: ch3:reliability\n",
    "\\beta = \\sum_{i=0}^{d-1} \\binom{n}{i} \\epsilon^i (1-\\epsilon)^{n-i}.\n",
    "```\n",
    "Crucially the assessment of $V(\\hat{z}_n)$ is possible a priori,\n",
    "although other techniques exist {cite}`barrera2016chance`. {cite}`care2015scenario`\n",
    "analyse the reliability of solutions of the maximum error loss functions\n",
    "({eq}`max-error-loss`) in the scenario framework when $\\hat{y}(x)$\n",
    "is convex in $x$ and the function weights.\n",
    "\n",
    "In the convex case, the a priori assessment is made possible by the fact\n",
    "that the number of support constraints (the number of constraints which\n",
    "if removed result in a more optimal solution) for a convex program is\n",
    "always bounded by the dimensionality of the design variable.\n",
    "{cite}`campi2018wait` explore this connection for convex programs in further\n",
    "detail, by analysing the number of support constraints after a solution\n",
    "is obtained. In fact, the bound in\n",
    "{eq}`ch3:reliability` if often overly conservative, because in\n",
    "many cases the number of support constraints is less than the\n",
    "dimensionality of the design variable, and hence a more accurate bound\n",
    "on the reliability of the IPM can be obtained. The improved bound is\n",
    "given by letting $\\epsilon$ be a function of the number of support\n",
    "constraints $s^*_n$ such that $\\epsilon(s^*_n)=1-t(s^*_n)$. Then for\n",
    "$0<\\beta<1$ and $0<s^*_n<d$ the equation\n",
    "```{math}\n",
    ":label: wait\n",
    "\\frac{\\beta}{n+1}\\sum_{m=k}^n{\\binom{m}{k}t^{m-k}-\\binom{n}{k}t^{n-k}}=0\n",
    "```\n",
    "has one solution, $t(k)$ in the interval $[0,1]$.\n",
    "\n",
    "This idea has a deep connection with the concept of regularisation in\n",
    "machine learning {cite}`campi2013random`. {cite}`scenarioiterative2019` demonstrates\n",
    "how the number of support constraints of a scenario program can be used\n",
    "to iteratively increase the number of sampled constraints, which\n",
    "requires fewer sampled constraints in total than\n",
    "{sec}`ch3:reliability` for equivalent $\\epsilon$ and $\\beta$.\n",
    "For a non-convex program, the number of support constraints is not\n",
    "necessarily less than the dimensionality of the design variable, and\n",
    "therefore a new approach is required, which we describe in the following\n",
    "section.\n",
    "\n",
    "#### Non-convex case\n",
    "\n",
    "{cite}`campi2018general` provide the following bound for the non-convex case:\n",
    "$P^n(V(\\hat{z}_n)>\\epsilon(s))<\\beta,$ where\n",
    "```{math}\n",
    ":label: theBound\n",
    "\\epsilon(s)=\n",
    "  \\begin{cases}\n",
    "    1, & \\text{for } s=n, \\\\\n",
    "    1-\\sqrt[n-s]{\\frac{\\beta}{n\\binom{n}{s}}}, & \\text{otherwise,}\n",
    "  \\end{cases}\n",
    "```  \n",
    "and $s$ is the cardinality of the support set (in\n",
    "other words, the number of support constraints). The behaviour of this\n",
    "bound is similar to the convex case since in general increasing $n$\n",
    "should increase the size of the support set.\n",
    "\n",
    "Finding the cardinality of the support set is in general a\n",
    "computationally expensive task, since the scenario program must be\n",
    "solved $n$ times. {cite}`campi2015non` present a time-efficient algorithm which\n",
    "only requires that the scenario problem is solved $s$ times.\n",
    "\n",
    "(sec:apost)=\n",
    "#### A posteriori frequentist analysis\n",
    "\n",
    "When data is available in abundance, as is typically the case in most\n",
    "machine learning tasks where a neural network is currently used,\n",
    "$V(\\hat{z}_n)$ can be evaluated more easily by using a test set to\n",
    "collect samples from $V(\\hat{z}_n)$. Estimating $V(\\hat{z}_n)$ is\n",
    "similar to estimating a probability of failure in the well known\n",
    "reliability theory. Therefore one can construct a Monte Carlo estimator\n",
    "of $V(\\hat{z}_n)$, or use more advanced techniques from reliability\n",
    "analysis if it is possible to interact with the data generating\n",
    "mechanism. For example, if the number of test data points is large we\n",
    "can use the normal approximation Monte Carlo estimator of $V(\\hat{z}_n)$\n",
    "with $V(\\hat{z}_n)\\approx \\frac{N_v}{N_t}$ and standard deviation\n",
    "$\\sqrt{\\frac{\\frac{N_v}{N_t}(1-\\frac{N_v}{N_t})}{N_t}}$, on a test set\n",
    "of size $N_t$, where $N_v$ data points fall outside the interval bounds\n",
    "of the neural network.\n",
    "\n",
    "A particularly robust method of estimating the probability of a binary\n",
    "outcome involves using the binomial confidence bounds. In this case\n",
    "specifically, one can bound $V(\\hat{z}_n)$ with the desired confidence\n",
    "using the binomial confidence bounds:\n",
    "$\\sum_{i=0}^{N_t-N_v}\\binom{N_t}{i}(1-\\underline{v})^i\\underline{v}^{N_t-i}=\\frac{\\beta}{2}$\n",
    "and\n",
    "$\\sum_{i=N_t-N_v}^{N_t}\\binom{N_t}{i}(1-\\overline{v})^i\\overline{v}^{N_t-i}=\\frac{\\beta}{2},$\n",
    "where\n",
    "$P(V(\\hat{z}_n)<\\overline{v} \\cap V(\\hat{z}_n)>\\underline{v})=\\beta$.\n",
    "Estimating $V(\\hat{z}_n)$ using a test set also offers the advantage\n",
    "that when the neural network is used for predictions on a different data\n",
    "set, $V(\\hat{z}_n)$ can be evaluated easily. If the value of\n",
    "$V(\\hat{z}_n)$ obtained on the test set is higher than that on the\n",
    "training dataset, one can apply regularisation in order to implicitly\n",
    "reduce the size of the support set and increase $V(\\hat{z}_n)$ on the\n",
    "test set (e.g. dropout regularisation, or $\\ell_2$ regularisation on the\n",
    "weights).\n",
    "\n",
    "This methodology is ideal for models with a complex training scheme,\n",
    "where determining the support set would be prohibitively expensive. Note\n",
    "that the probabilistic assessment of the reliability of the model takes\n",
    "place separately from the training of the regression model, such that it\n",
    "is still robust, even if there is a problem with the regression model\n",
    "training. This is an important advantage over Variational Inference\n",
    "methods which are often used with neural networks.\n",
    "\n",
    "### Software for interval predictor models\n",
    "\n",
    "{cite}`patelli2017cossan` describe the first open source software\n",
    "implementation of interval predictor models in the generalised\n",
    "uncertainty quantification software OpenCossan, which is\n",
    "written in Matlab. The OpenCossan software\n",
    "allows convex IPMs to be trained, with hyper-rectangular uncertainty\n",
    "sets. The OpenCossan software is modular and allows the\n",
    "IPMs to be automatically trained as approximations of expensive\n",
    "engineering models, and then used in other engineering calculations,\n",
    "e.g. design optimisation. A partial Python port of the\n",
    "OpenCossan IPM code was released as open source software\n",
    "by {cite}`sadeghi_pyipm`.\n",
    "\n",
    "The introduced software has been applied in {cite}`brandt2017meta`, to study\n",
    "fatigue damage estimation of offshore wind turbines jacket substructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worked example : linear regression\n",
    "\n",
    "We repeat the previous linear regression example using the `PyIPM` Interval Predictor Model library.\n",
    "Since the IPM makes fewer assumptions than the parametric model we will require more data to learn an effective model.\n",
    "Therefore we will generate training data from a toy function $1000 x^2 + \\epsilon$, where $\\epsilon$ is randomly distributed noise with standard deviation $20000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres   k/t\n",
      " 0:  0.0000e+00  1.1867e-10  2e+06  1e-01  1e+02  1e+00\n",
      " 1:  1.6651e+04  1.7531e+04  7e+05  4e-02  3e+01  9e+02\n",
      " 2:  2.1172e+04  2.1208e+04  3e+04  2e-03  1e+00  4e+01\n",
      " 3:  2.0265e+04  2.0299e+04  2e+04  1e-03  8e-01  3e+01\n",
      " 4:  1.9733e+04  1.9755e+04  7e+03  4e-04  3e-01  2e+01\n",
      " 5:  1.9535e+04  1.9542e+04  1e+03  9e-05  7e-02  7e+00\n",
      " 6:  1.9470e+04  1.9470e+04  4e+01  3e-06  2e-03  2e-01\n",
      " 7:  1.9469e+04  1.9469e+04  4e-01  3e-08  2e-05  2e-03\n",
      " 8:  1.9469e+04  1.9469e+04  4e-03  3e-10  2e-07  2e-05\n",
      " 9:  1.9469e+04  1.9469e+04  4e-05  3e-12  2e-09  2e-07\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a test set generated from the same function as the training data, our model predictions will be enclose the test set with probability greater than 0.7704137287382764\n"
     ]
    }
   ],
   "source": [
    "import PyIPM\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rainfall = 13 * np.random.rand(100).reshape(-1, 1)\n",
    "umbrellas = 1000 * rainfall.squeeze(-1) ** 2 + 20000 * np.random.rand(100)\n",
    "\n",
    "model = PyIPM.IPM(polynomial_degree=2)\n",
    "\n",
    "model.fit(rainfall, umbrellas)\n",
    "\n",
    "x_plot = np.arange(0, 13, 0.1)\n",
    "upper_bound, lower_bound = model.predict(x_plot.reshape(-1, 1))\n",
    "\n",
    "plt.scatter(rainfall, umbrellas, label=\"Training Data\")\n",
    "plt.fill_between(\n",
    "    x_plot,\n",
    "    lower_bound.squeeze(-1),\n",
    "    upper_bound.squeeze(-1),\n",
    "    alpha=0.3,\n",
    "    label=\"IPM\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"For a test set generated from the same function as the training data, \"\n",
    "      \"our model predictions will be enclose the test set with probability \"\n",
    "      \"greater than {}\".format(model.get_model_reliability()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the benefits of Interval Predictor Models: few assumptions are required, but a model which fits the data well can be obtained, alongside rigorous uncertainty quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}